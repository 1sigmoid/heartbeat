{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing necessary shit\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Making a list of all the files in the dataset biorxiv_medrxiv directory\n",
    "\"\"\"\n",
    "\n",
    "entries = os.listdir(\"./../../datasets/cord19/biorxiv_medrxiv/biorxiv_medrxiv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "initializing a list for storing \n",
    "all the dictionaries made from the json files\n",
    "\"\"\"\n",
    "datals = [] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "creating a string to append the base directory\n",
    "\n",
    "\"\"\"\n",
    "s = \"./../../datasets/cord19/biorxiv_medrxiv/biorxiv_medrxiv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "reading the files from the given directory\n",
    "\n",
    "\"\"\"\n",
    "for i in entries:\n",
    "    with open(s+i) as f:\n",
    "        dat = json.load(f)\n",
    "        datals.append(dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters:\n",
    "list abstractls - storing the abstract text from all the given documents\n",
    "list bodyls - storing the body text from all the given docs\n",
    "list temp_ls - to store temp data while reading all docs\n",
    "\n",
    "\"\"\"\n",
    "abstractls = [] \n",
    "bodyls = []\n",
    "temp_ls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(datals)):\n",
    "    current_data = datals[i] #sets the working file\n",
    "    \"\"\"\n",
    "    abstract is a list containing dictionaries\n",
    "    we select only the text from each dictionary in the abstract\n",
    "    with a length greater than 100\n",
    "    \n",
    "    abstract = [\n",
    "    {\n",
    "        \"text\":\n",
    "    }, \n",
    "    \n",
    "    {\n",
    "        \"text\":\n",
    "    },\n",
    "    \n",
    "    ]\n",
    "    \n",
    "    \"\"\"\n",
    "    for j in range(len(current_data[\"abstract\"])):\n",
    "        current_block = current_data[\"abstract\"][j]\n",
    "        #selects each dictionary in the abstract list\n",
    "    \n",
    "        \n",
    "        text = current_block[\"text\"] \n",
    "        #this selects the text in each block of data\n",
    "        \n",
    "        if len(text) > 200:\n",
    "            # to ensure that random bits of data do not creep in to the code\n",
    "            temp_ls.append(text)\n",
    "    # now we append the list of abstracts from EACH file, to the abstractls\n",
    "    abstractls.append(temp_ls)\n",
    "    \n",
    "    #then we delete it\n",
    "    temp_ls = []\n",
    "    \n",
    "    \n",
    "    #now iterating through the body text of each file\n",
    "    \n",
    "    \"\"\"\n",
    "    body_text is a list containing dictionaries\n",
    "    we select only the text from each dictionary in the abstract\n",
    "    with a length greater than 200 chars\n",
    "    \n",
    "    body_text = [\n",
    "    {\n",
    "        \"text\":\n",
    "    }, \n",
    "    \n",
    "    {\n",
    "        \"text\":\n",
    "    },\n",
    "    \n",
    "    ]\n",
    "    \n",
    "    \"\"\"\n",
    "    for k in range(len(current_data[\"body_text\"])):\n",
    "        \n",
    "        # selecting the block in the body text\n",
    "        current_block = current_data[\"body_text\"][k]\n",
    "        text = current_block[\"text\"]\n",
    "        if len(text) > 200:\n",
    "            temp_ls.append(text)\n",
    "    \n",
    "    bodyls.append(temp_ls)\n",
    "    temp_ls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here, we go through both abstractls and the bodyls, convert all the text to lowercase\n",
    "and then use regex to remove numbers and special chars.\n",
    "\n",
    "\n",
    "Then, we convert words to their root forms using, and we ignore parts of speech\n",
    "like the, for, etc, using stopwords\n",
    "\"\"\"\n",
    "ps = PorterStemmer()\n",
    "for i in range(len(bodyls)):\n",
    "    current_list = bodyls[i]\n",
    "    for j in range(len(current_list)):\n",
    "        bodyls[i][j] = bodyls[i][j].lower()\n",
    "        bodyls[i][j] = re.sub('[^a-zA-Z]', ' ', bodyls[i][j])\n",
    "        bodyls[i][j] = bodyls[i][j].split()\n",
    "        bodyls[i][j] = [ps.stem(word) for word in bodyls[i][j] if not word in set(stopwords.words('english'))]\n",
    "        bodyls[i][j] = ''.join(bodyls[i][j])\n",
    "    clist2 = abstractls[i]\n",
    "    for k in range(len(clist2)):\n",
    "        abstractls[i][k] = abstractls[i][k].lower()\n",
    "        abstractls[i][k] = re.sub('[^a-zA-Z]', ' ', abstractls[i][k])\n",
    "        abstractls[i][k] = abstractls[i][k].split()\n",
    "        abstractls[i][k] = [ps.stem(word) for word in abstractls[i][k] if not word in set(stopwords.words('english'))]\n",
    "        abstractls[i][k] = ' '.join(abstractls[i][k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
